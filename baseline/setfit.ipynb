{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(678, 10)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from setfit import SetFitModel, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from setfit import Trainer\n",
    "\n",
    "all_valids = pd.read_csv('../data/train_valid_all.csv')\n",
    "print(all_valids.shape)\n",
    "\n",
    "all_valids = all_valids[['Response', 'Label']]\n",
    "\n",
    "# Split all_valids into train, test, and validation datasets\n",
    "train_samples = all_valids.groupby('Label').apply(lambda x: x.sample(5)).reset_index(drop=True)\n",
    "remaining_samples = all_valids.drop(train_samples.index).reset_index(drop=True)\n",
    "test_samples = remaining_samples.groupby('Label').apply(lambda x: x.sample(frac=0.67)).reset_index(drop=True)\n",
    "validation_samples = remaining_samples.drop(test_samples.index).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (25, 2)\n",
      "test shape:  (437, 2)\n",
      "validation shape:  (216, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \", train_samples.shape)\n",
    "print(\"test shape: \", test_samples.shape)\n",
    "print(\"validation shape: \", validation_samples.shape)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_samples)\n",
    "val_dataset = Dataset.from_pandas(validation_samples)\n",
    "test_dataset = Dataset.from_pandas(test_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Response', 'Label'],\n",
       "        num_rows: 25\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['Response', 'Label'],\n",
       "        num_rows: 216\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Response', 'Label'],\n",
       "        num_rows: 437\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
    "model.labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "train_dataset = dataset_dict[\"train\"]\n",
    "test_dataset = dataset_dict[\"test\"]\n",
    "val_dataset = dataset_dict[\"validation\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Response', 'Label'],\n",
       "    num_rows: 25\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying column mapping to the training dataset\n",
      "/Users/kaylahuang/opt/anaconda3/envs/mercor/lib/python3.12/site-packages/datasets/utils/_dill.py:379: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0070f986964baeb2046826fdad14b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    batch_size=8,\n",
    "    num_epochs=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    # eval_dataset=val_dataset,\n",
    "    column_mapping={\"Response\": \"text\", \"Label\": \"label\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 500\n",
      "  Batch size = 8\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34eec2799ff740adbb2a0620b698a0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8004bd16c0a64fdbaa8d6fcad051faac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mercor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
